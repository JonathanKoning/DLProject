Balanced review counts

All Beauty                        318
Prime Pantry                    16270
Office Products                120380
Grocery and Gourmet Food       210660
Pet Supplies                   538705
Home and Kitchen              1447320



# Embeddings

## all-87k-300d.vec

 paths = [
    "data/csv/all-beauty-test.csv",
    "data/csv/all-beauty-train.csv",
    "data/csv/grocery-and-gourmet-food-test.csv",
    "data/csv/grocery-and-gourmet-food-train.csv",
    "data/csv/home-and-kitchen-test.csv",
    "data/csv/home-and-kitchen-train.csv",
    "data/csv/office-products-train.csv",
    "data/csv/office-products-test.csv",
    "data/csv/pet-supplies-train.csv",
    "data/csv/pet-supplies-test.csv",
    "data/csv/prime-pantry-train.csv",
]

word2vec = Word2Vec(
    sentences,
    sg= 1,
    size= 300,         # Dimension of the word embedding vectors
    window= 5,    # Radius of skip-gram / cbow window from current word
    min_count= 5,
    iter= 5
)

## all-119k-300d.vec

paths = [
    "data/csv/all-beauty-test.csv",
    "data/csv/all-beauty-train.csv",
    "data/csv/grocery-and-gourmet-food-test.csv",
    "data/csv/grocery-and-gourmet-food-train.csv",
    "data/csv/home-and-kitchen-test.csv",
    "data/csv/home-and-kitchen-train.csv",
    "data/csv/office-products-train.csv",
    "data/csv/office-products-test.csv",
    "data/csv/pet-supplies-train.csv",
    "data/csv/pet-supplies-test.csv",
    "data/csv/prime-pantry-train.csv",
]

word2vec = Word2Vec(
    sentences,
    sg= 1,
    size= 300,         # Dimension of the word embedding vectors
    window= 5,    # Radius of skip-gram / cbow window from current word
    min_count= 3,
    iter= 5
)

## food-36k-300d

paths = [
    "data/csv/grocery-and-gourmet-food-test.csv",
    "data/csv/grocery-and-gourmet-food-train.csv",
    "data/csv/prime-pantry-train.csv",
]

word2vec = Word2Vec(
    sentences,
    sg= 1,
    size= 300,         # Dimension of the word embedding vectors
    window= 5,    # Radius of skip-gram / cbow window from current word
    min_count= 3,
    iter= 5
)


=== Size: 100 ===
Test loss/accuracy(0.006915222434854845, 0.08349609375)
Test loss/accuracy(0.007025339226057246, 0.08447265625)
Test loss/accuracy(0.007077533033861763, 0.08740234375)
Test loss/accuracy(0.0071143325441106325, 0.08349609375)

Train loss/accuracy
(0.00615746837152064, 0.09921875)
Test loss/accuracy
(0.0071143325441106325, 0.08349609375)

=== Size: 200 ===
Test loss/accuracy(0.007153355694129587, 0.08544921875)
Test loss/accuracy(0.007213953771479403, 0.09375)
Test loss/accuracy(0.007243567885098973, 0.0888671875)
Test loss/accuracy(0.007257310906050064, 0.09326171875)

Train loss/accuracy
(0.0061454393922861505, 0.1015625)
Test loss/accuracy
(0.007257310906050064, 0.09326171875)


=== Size: 300 ===
Test loss/accuracy(0.007281287557004967, 0.08349609375)
Test loss/accuracy(0.007307068858724383, 0.0986328125)
Test loss/accuracy(0.007302603053625752, 0.10009765625)
Test loss/accuracy(0.0072837593703174545, 0.10888671875)

Train loss/accuracy
(0.006109472933302969, 0.11591796875)
Test loss/accuracy
(0.0072837593703174545, 0.10888671875)


=== Size: 400 ===
Test loss/accuracy(0.007355877175730787, 0.0869140625)
Test loss/accuracy(0.0073508212034786346, 0.09814453125)
Test loss/accuracy(0.007316468593921674, 0.099609375)
Test loss/accuracy(0.007252678532664598, 0.111328125)

Train loss/accuracy
(0.0060091317030338725, 0.119921875)
Test loss/accuracy
(0.007252678532664598, 0.111328125)


=== Size: 500 ===
Test loss/accuracy(0.007387454010214337, 0.08447265625)
Test loss/accuracy(0.0073555985247287115, 0.09619140625)
Test loss/accuracy(0.007292104428357968, 0.103515625)
Test loss/accuracy(0.007190923395986842, 0.12548828125)

Train loss/accuracy
(0.005933551483843372, 0.1341796875)
Test loss/accuracy
(0.007190923395986842, 0.12548828125)



Using: cuda:0

 === Size: 100 ===
Epoch 1 Loss: 0.05082481805147359
Epoch 2 Loss: 0.046681486642805206
Epoch 3 Loss: 0.03788565077546242
Epoch 4 Loss: 0.032710263824632636
Epoch 5 Loss: 0.031334222519076076
Test loss/accuracy(0.006915222434854845, 0.08349609375)
Epoch 6 Loss: 0.031135046662246396
Epoch 7 Loss: 0.031061814206053175
Epoch 8 Loss: 0.0310051300686957
Epoch 9 Loss: 0.030979441215575998
Epoch 10 Loss: 0.030964307224954708
Test loss/accuracy(0.007025339226057246, 0.08447265625)
Epoch 11 Loss: 0.030953646040002537
Epoch 12 Loss: 0.03094369338982748
Epoch 13 Loss: 0.030932945061360434
Epoch 14 Loss: 0.030922354595758334
Epoch 15 Loss: 0.030910187872987004
Test loss/accuracy(0.007077533033861763, 0.08740234375)
Epoch 16 Loss: 0.03089708939923934
Epoch 17 Loss: 0.030883743499336275
Epoch 18 Loss: 0.030870576317988896
Epoch 19 Loss: 0.03085775476362976
Epoch 20 Loss: 0.030845426171113702
Test loss/accuracy(0.0071143325441106325, 0.08349609375)
Train loss/accuracy
(0.00615746837152064, 0.09921875)
Test loss/accuracy
(0.0071143325441106325, 0.08349609375)

 === Size: 200 ===
Epoch 1 Loss: 0.0503815996220355
Epoch 2 Loss: 0.039873052804338414
Epoch 3 Loss: 0.03172501944471538
Epoch 4 Loss: 0.03126150769916597
Epoch 5 Loss: 0.031030358578987668
Test loss/accuracy(0.007153355694129587, 0.08544921875)
Epoch 6 Loss: 0.03099036687645
Epoch 7 Loss: 0.03097060026845266
Epoch 8 Loss: 0.030959966627063427
Epoch 9 Loss: 0.030953794665711788
Epoch 10 Loss: 0.030947682454663675
Test loss/accuracy(0.007213953771479403, 0.09375)
Epoch 11 Loss: 0.0309430509895464
Epoch 12 Loss: 0.030937266893582723
Epoch 13 Loss: 0.030931400013299807
Epoch 14 Loss: 0.030924331231424088
Epoch 15 Loss: 0.030914980404120905
Test loss/accuracy(0.007243567885098973, 0.0888671875)
Epoch 16 Loss: 0.030903227054013074
Epoch 17 Loss: 0.03088981424765748
Epoch 18 Loss: 0.0308745581101406
Epoch 19 Loss: 0.030874590255722614
Epoch 20 Loss: 0.03085396000732782
Test loss/accuracy(0.007257310906050064, 0.09326171875)
Train loss/accuracy
(0.0061454393922861505, 0.1015625)
Test loss/accuracy
(0.007257310906050064, 0.09326171875)

 === Size: 300 ===
Epoch 1 Loss: 0.04955584845427157
Epoch 2 Loss: 0.03492674915476135
Epoch 3 Loss: 0.03155456877264297
Epoch 4 Loss: 0.031118257094809507
Epoch 5 Loss: 0.031031250608419384
Test loss/accuracy(0.007281287557004967, 0.08349609375)
Epoch 6 Loss: 0.031014234836322936
Epoch 7 Loss: 0.03099546455963451
Epoch 8 Loss: 0.03098531176319178
Epoch 9 Loss: 0.030971892467960793
Epoch 10 Loss: 0.030961096456254996
Test loss/accuracy(0.007307068858724383, 0.0986328125)
Epoch 11 Loss: 0.03094827198211536
Epoch 12 Loss: 0.030935566710572893
Epoch 13 Loss: 0.030920445101239834
Epoch 14 Loss: 0.030902514676799775
Epoch 15 Loss: 0.03087893595816927
Test loss/accuracy(0.007302603053625752, 0.10009765625)
Epoch 16 Loss: 0.0308510576043305
Epoch 17 Loss: 0.03082001279092643
Epoch 18 Loss: 0.030793104311299845
Epoch 19 Loss: 0.030761684411464138
Epoch 20 Loss: 0.030700532196796717
Test loss/accuracy(0.0072837593703174545, 0.10888671875)
Train loss/accuracy
(0.006109472933302969, 0.11591796875)
Test loss/accuracy
(0.0072837593703174545, 0.10888671875)

 === Size: 400 ===
Epoch 1 Loss: 0.04861425326606644
Epoch 2 Loss: 0.03318811487524907
Epoch 3 Loss: 0.031471623593136655
Epoch 4 Loss: 0.031106472004308404
Epoch 5 Loss: 0.031056377166978594
Test loss/accuracy(0.007355877175730787, 0.0869140625)
Epoch 6 Loss: 0.031034164007962696
Epoch 7 Loss: 0.031005957610145633
Epoch 8 Loss: 0.0309807923824334
Epoch 9 Loss: 0.03095574935606981
Epoch 10 Loss: 0.030931513444741158
Test loss/accuracy(0.0073508212034786346, 0.09814453125)
Epoch 11 Loss: 0.030908999590052
Epoch 12 Loss: 0.030888477778017842
Epoch 13 Loss: 0.030834008861386857
Epoch 14 Loss: 0.030779029278080412
Epoch 15 Loss: 0.03071793047357708
Test loss/accuracy(0.007316468593921674, 0.099609375)
Epoch 16 Loss: 0.030645761349848685
Epoch 17 Loss: 0.03056617234655742
Epoch 18 Loss: 0.03049284463107578
Epoch 19 Loss: 0.030409230726363378
Epoch 20 Loss: 0.030266127790135697
Test loss/accuracy(0.007252678532664598, 0.111328125)
Train loss/accuracy
(0.0060091317030338725, 0.119921875)
Test loss/accuracy
(0.007252678532664598, 0.111328125)

 === Size: 500 ===
Epoch 1 Loss: 0.046965009579172996
Epoch 2 Loss: 0.03258355106156445
Epoch 3 Loss: 0.03139341380406419
Epoch 4 Loss: 0.031120503551635745
Epoch 5 Loss: 0.031104975499354676
Test loss/accuracy(0.007387454010214337, 0.08447265625)
Epoch 6 Loss: 0.031063870817961935
Epoch 7 Loss: 0.031030280349006296
Epoch 8 Loss: 0.030989423888834574
Epoch 9 Loss: 0.030954587060627013
Epoch 10 Loss: 0.030916891656927552
Test loss/accuracy(0.0073555985247287115, 0.09619140625)
Epoch 11 Loss: 0.030870611576822533
Epoch 12 Loss: 0.030819614183994686
Epoch 13 Loss: 0.030757616975417568
Epoch 14 Loss: 0.030684968557434352
Epoch 15 Loss: 0.030599669470954383
Test loss/accuracy(0.007292104428357968, 0.103515625)
Epoch 16 Loss: 0.03049729516027887
Epoch 17 Loss: 0.030381681126502785
Epoch 18 Loss: 0.030250209469322036
Epoch 19 Loss: 0.030101281207867835
Epoch 20 Loss: 0.02993993474931001
Test loss/accuracy(0.007190923395986842, 0.12548828125)
Train loss/accuracy
(0.005933551483843372, 0.1341796875)
Test loss/accuracy
(0.007190923395986842, 0.12548828125)

=== Size: 600 ===
Epoch 1 Loss: 0.046057789672587224
Epoch 2 Loss: 0.03270124107177258
Epoch 3 Loss: 0.031351111150436616
Epoch 4 Loss: 0.031142749444074528
Epoch 5 Loss: 0.0310971001636448
Test loss/accuracy(0.007341529563924063, 0.08740234375)
Epoch 6 Loss: 0.031053623637994476
Epoch 7 Loss: 0.031010262743754687
Epoch 8 Loss: 0.030970843957959814
Epoch 9 Loss: 0.03093668757867395
Epoch 10 Loss: 0.030897012087765043
Test loss/accuracy(0.00729990674218328, 0.099609375)
Epoch 11 Loss: 0.030846145130883292
Epoch 12 Loss: 0.03078439289332122
Epoch 13 Loss: 0.030708360444487364
Epoch 14 Loss: 0.03062668826655934
Epoch 15 Loss: 0.030520022014984237
Test loss/accuracy(0.007235836966423282, 0.10888671875)
Epoch 16 Loss: 0.030390999668936027
Epoch 17 Loss: 0.030240456736288703
Epoch 18 Loss: 0.030062618303519577
Epoch 19 Loss: 0.029867919762161497
Epoch 20 Loss: 0.029638959526318783
Test loss/accuracy(0.007105371637823279, 0.13427734375)
Train loss/accuracy
(0.005867817804575926, 0.147265625)
Test loss/accuracy
(0.007105371637823279, 0.13427734375)

=== Size: 700 ===
Epoch 1 Loss: 0.04522019968456704
Epoch 2 Loss: 0.032730998809650164
Epoch 3 Loss: 0.03131547128703163
Epoch 4 Loss: 0.031141731005509786
Epoch 5 Loss: 0.031074173793691644
Test loss/accuracy(0.007248513887745807, 0.099609375)
Epoch 6 Loss: 0.031021924517266805
Epoch 7 Loss: 0.03096905692791263
Epoch 8 Loss: 0.03091745896254886
Epoch 9 Loss: 0.030868924348313183
Epoch 10 Loss: 0.03080967719595146
Test loss/accuracy(0.007225333272152941, 0.10205078125)
Epoch 11 Loss: 0.03073881366920161
Epoch 12 Loss: 0.030651815895002998
Epoch 13 Loss: 0.030545678004802027
Epoch 14 Loss: 0.030417642028270797
Epoch 15 Loss: 0.03026510793282449
Test loss/accuracy(0.007146375727363539, 0.11474609375)
Epoch 16 Loss: 0.03008515430770674
Epoch 17 Loss: 0.029878815491878673
Epoch 18 Loss: 0.02963488221944905
Epoch 19 Loss: 0.029364295117540663
Epoch 20 Loss: 0.029089995960050373
Test loss/accuracy(0.007012368045221354, 0.14453125)
Train loss/accuracy
(0.005748971689033495, 0.15771484375)
Test loss/accuracy
(0.007012368045221354, 0.14453125)

=== Size: 800 ===
Epoch 1 Loss: 0.04461592901557266
Epoch 2 Loss: 0.03269402391750831
Epoch 3 Loss: 0.03129292799778492
Epoch 4 Loss: 0.031152300314897387
Epoch 5 Loss: 0.031068552238001666
Test loss/accuracy(0.00721565257477653, 0.099609375)
Epoch 6 Loss: 0.031006165845520538
Epoch 7 Loss: 0.030945968025216215
Epoch 8 Loss: 0.030889761792442873
Epoch 9 Loss: 0.030828832657390566
Epoch 10 Loss: 0.030758369774292235
Test loss/accuracy(0.007182632860807458, 0.1025390625)
Epoch 11 Loss: 0.03067035006408912
Epoch 12 Loss: 0.030565321081864605
Epoch 13 Loss: 0.030433394741269968
Epoch 14 Loss: 0.030278623319279017
Epoch 15 Loss: 0.030097162651545727
Test loss/accuracy(0.007103670147681759, 0.11865234375)
Epoch 16 Loss: 0.029884383630058672
Epoch 17 Loss: 0.02963976898023414
Epoch 18 Loss: 0.02938091816240553
Epoch 19 Loss: 0.029071982435761347
Epoch 20 Loss: 0.028760220887954772
Test loss/accuracy(0.006965119630839929, 0.14453125)
Train loss/accuracy
(0.0056831705195229554, 0.16171875)
Test loss/accuracy
(0.006965119630839929, 0.14453125)

=== Size: 900 ===
Epoch 1 Loss: 0.04421920588310796
Epoch 2 Loss: 0.03266270412646487
Epoch 3 Loss: 0.03128496231704674
Epoch 4 Loss: 0.031165421946877377
Epoch 5 Loss: 0.03104536912089883
Test loss/accuracy(0.007190936151066624, 0.08447265625)
Epoch 6 Loss: 0.030982646035445028
Epoch 7 Loss: 0.030908632974645075
Epoch 8 Loss: 0.03084806880771134
Epoch 9 Loss: 0.030776491259316776
Epoch 10 Loss: 0.030690975853368583
Test loss/accuracy(0.00716740083822494, 0.10693359375)
Epoch 11 Loss: 0.030589739691392965
Epoch 12 Loss: 0.030467508640131192
Epoch 13 Loss: 0.030318966328396462
Epoch 14 Loss: 0.030142521361384417
Epoch 15 Loss: 0.029934955522787174
Test loss/accuracy(0.00706587282712953, 0.125)
Epoch 16 Loss: 0.029690708324580442
Epoch 17 Loss: 0.029412265632251793
Epoch 18 Loss: 0.029104814422865954
Epoch 19 Loss: 0.028792247022303208
Epoch 20 Loss: 0.028429816942041566
Test loss/accuracy(0.00696281070215766, 0.1533203125)
Train loss/accuracy
(0.005603536527929646, 0.1708984375)
Test loss/accuracy
(0.00696281070215766, 0.1533203125)

=== Size: 1000 ===
Epoch 1 Loss: 0.0440013415576133
Epoch 2 Loss: 0.032616370446285695
Epoch 3 Loss: 0.03130030036435357
Epoch 4 Loss: 0.03116236174727814
Epoch 5 Loss: 0.03105132193366197
Test loss/accuracy(0.0071843917334610975, 0.0888671875)
Epoch 6 Loss: 0.030978467179075535
Epoch 7 Loss: 0.030904371822118713
Epoch 8 Loss: 0.030837453742667817
Epoch 9 Loss: 0.030767069847376927
Epoch 10 Loss: 0.030679563420287714
Test loss/accuracy(0.007163290731310983, 0.1064453125)
Epoch 11 Loss: 0.030575121029805162
Epoch 12 Loss: 0.03044731289181847
Epoch 13 Loss: 0.030287576781338605
Epoch 14 Loss: 0.030090955473929416
Epoch 15 Loss: 0.029868350053938307
Test loss/accuracy(0.007051464128022848, 0.12890625)
Epoch 16 Loss: 0.029594572638506966
Epoch 17 Loss: 0.02926586469415123
Epoch 18 Loss: 0.028918649479552708
Epoch 19 Loss: 0.02852991824504266
Epoch 20 Loss: 0.028140823250615635
Test loss/accuracy(0.006944316026819405, 0.15283203125)
Train loss/accuracy
(0.005546483757441935, 0.17021484375)
Test loss/accuracy
(0.006944316026819405, 0.15283203125)